\input{settings.tex}
\linespread{1.6} % Space between lines
\parindent=0pt % line up
\begin{document}
	\section*{Chapter 2 Linear Transformations, Null Spaces, and Ranges}	
	\subsection*{\S\,2-1 Linear transformation}
\begin{defn}[Definition of Linear Transformation]
$ $\\	Let $\mathrm{V}$ and $\mathrm{W}$ be vector spaces (over $\mathrm{F}$). We call a function $\mathrm{T}: \mathrm{V}  \rightarrow  \mathrm{W}$    a linear transformation from $\mathrm{V}$ to $\mathrm{W}$ if, for all x, y $\in$ $\mathrm{V}$ and c $\in$ $\mathrm{F}$, we have

\begin{enumerate}
	\item [(a)]   $\mathrm{T}$(x + y) = $\mathrm{T}$(x) + $\mathrm{T}$(y) 
	\item [(b)]    $\mathrm{T}$($\mathrm{c}$x) = $\mathrm{c}\mathrm{T}$(x)
\end{enumerate} 
\end{defn}

\begin{defn}[Definition of nullity and rank]
$ $\\	Let $\mathrm{V}$ and $\mathrm{W}$ be vector spaces and let $\mathrm{T}: \mathrm{V}  \rightarrow  \mathrm{W}$ be linear. If N(T) and R(T) are finite-dimensional, then we define the nullity of T, denoted nullity(T), and the rank of T, denoted rank(T), to be the dimensions of N(T) and R(T), respectively.
\end{defn}

\begin{thm*}
$ $ \\ 	Let V and W be vector spaces and $\mathrm{T}: \mathrm{V}  \rightarrow  \mathrm{W}$ be linear. Then N(T) and R(T) are subspaces of $\mathrm{V}$ and $\mathrm{W}$, respectively.
\end{thm*}

\begin{thm*}
$ $\\
 Let V and W be vector spaces, and let $\mathrm{T} : \mathrm{V}  \rightarrow \mathrm{W}$ be linear. If $\beta = \{ v_1,v_2,\cdots,v_n \}$ is a basis for $\mathrm{V}$ , then $ \mathrm{R}(\mathrm{T}) = \mathrm{span}(\mathrm{T}(\beta)) = \mathrm{span}(\{\mathrm{T}(v_1), \mathrm{T}(v_2), . . . , \mathrm{T}(v_n)\})$.

\end{thm*}

\begin{example}[11] %Example 11
	Question : \\
	Let T : $\mathrm{P}_2(R) \rightarrow  \mathrm{P}_3(R) $ be the linear trans formation defined by 
	
		
	 \[T(f(x)) = 2f'(x) + \int_0^x3 f(t) dt \]
	
		\begin{sol*} 
$ $ \\ 	
Now $\mathrm{R}(\mathrm{T}) = \mathrm{Span}( \{ \mathrm{T}(1), \mathrm{T}(x), \mathrm{T}(x^2 )  ) = \mathrm{Span}( \{ 3x,  2+ \frac{3}{2}  x^2 , 4x + x^3 \} ) $. 

 \noindent Since \{ $3x$ , $ 2 + \frac{3}{2} x^2$, $4x + x^3$ \} is linearly independent, rank($\mathrm{T}$) = 3. Since
2
$\dim(P_3(\R)) = 4$ , T is not onto. From the dimension theorem (Thm 2.3) , nullity(T) +
3 = 3. So nullity(T) = 0, and therefore, N(T) = {0}. We conclude from Theorem 2.4 that T is one-to-one.

	\end{sol*}

	\end{example}
\begin{example}[12] %Example 12
	 Question : \\ Let $\mathrm{T}: \mathrm{F}^2 \rightarrow \mathrm{F}^2 $ be the linear transformation defined by 
	 
	 \[T(a_1, a_2) = (a_1 + a_2, a_1)\]

	\begin{sol*} 
$ $ \\
		It is easy to see that N(T) = \{ 0 \} ; so T is one-to-one. Hence Theorem 2.5 tells us that T must be onto. 
	\end{sol*}

\end{example}

\begin{thm*}[2.3 Dimension Theorem]
$ $ \\	
Let V and W be vector spaces,
and let $ \mathrm{T} : \mathrm{V}  \rightarrow  \mathrm{W} $ be linear. \\ If V is finite-dimensional, then
 
 
 \[\rm	nullity(T) + rank(T) = dim(V).\]


\end{thm*}

\begin{thm*}[2.4]
$ $ \\	Let V and W be vector spaces, and let $\rm T: V  \rightarrow  W$ be
linear. Then T is one-to-one if and only if N(T) = {0 }.

\end{thm*}

\begin{thm*}[2.5]
$ $ \\	 Let V and W be vector spaces of equal (finite) dimension, and let $\rm T: V  \rightarrow  W$ be linear. Then the following are equivalent.
\begin{enumerate} 
	\item[(a)] T is one-to-one. 
	\item[(b)] T is onto.
	\item[(c)] rank(T) = dim(V).

\end{enumerate}

\end{thm*}

\begin{example}
	Let $\rm T : \R^2\longrightarrow \R^3 $ , $\rm T(a_1,a_2) = (a_1+a_2 , 0 , 2a_1-a_2)$ , determine that $\rm T $ is linear , 1-1 , onto or not.
	\begin{sol*}
		 $ $
		\begin{itemize}
			\item Calim : $\rm T$ is linear.\newline
			Let $ x =(a_1,a_2) \,,\, y= (b_1,b_2)$ 
				
				\(\begin{aligned} \rm T(c x+y) &=\rm T\left(c\left(a_{1}, a_{2}\right)+\left(b_{1}, b_{2}\right)\right)= T\left(ca_{1}+b_{1}, ca_{2}+b_{2}\right) \\ &=\rm \left(c a_{1}+b_{1}+c a_{2}+b_{2}, 0,2 c a_{1}+2 b_{1}-ca_{2}-b_{2}\right) \\ &=\rm \left(c\left(a_{1}+a_{2}\right)+\left(b_{1}+b_{2}\right), 0, c\left(2 a_{1}-a_{2}\right)+\left(2 b_{1}-b_{2}\right)\right) \\ &=\rm c\left(a_{1}+a_{2}, 0,2 a_{1}-a_{2}\right)+\left(b_{1}+b_{2}, 0,2 b_{1}-b_{2}\right) \\ &=\rm c T(x)+T (y) \end{aligned}\)
				
			$\therefore \rm T $ is linear
			\item 1-1 and onto 	
			
			By Thm 2.2 in text book choose a basis for $\R^2 , \beta = \{(1,0) , (0,1)\}$
			
			$\rm R(T) = span\left(T(\beta)\right) = span(\left\{T(1,0) , T(0,1)\right\}) = span\left((1,0,-1), (1,0,-2)\right)$ 
			
			Clearly it is L.I. $\rm\implies rank(T) = 2$ , and apply the Dimension Theorem $\rm rank(T)=2\neq3=\dim(\R^3) $, and $\rm nullitily(T) = 1 $ , then it is not onto.
			
			By Thm 2.4  it is not one to one.
			
		\end{itemize}
	\end{sol*}
		\end{example}
		\begin{example}
		Let \(\rm V\) and \(\rm W\) be vector spaces, let \(\mathrm{T}:\rm  V \rightarrow W\) be linear, and let
\(\left\{w_{1}, w_{2}, \ldots, w_{k}\right\}\) be a linearly independent subset of \(\rm R(T)\). Prove that
if \(S=\left\{v_{1}, v_{2}, \ldots, v_{k}\right\}\) is chosen so that \(\mathrm{T}\left(v_{i}\right)=w_{i}\) for \(i=1,2, \ldots, k\),
then \(S\) is linearly independent.
\begin{sol*}$ $
$ $\\
Calim : $\sum_{i=1}^n a_iv_i = 0\implies a_1 = a_2 = a_3 =\cdots =a_n = 0 $ 


Let \(\sum_{i=1}^{n} a_{i} v_{i}=0\)
then \(\mathrm{T}\left(\sum_{i=1}^{n} a_{i} v_{i}\right)=0\)
$ $\\
Since \(\rm T\) is linear , \(\mathrm{T}\left(\sum_{i=1}^{n} a_{i} v_{i}\right)=\sum_{i=1}^{n} a_{i} \mathrm{T}\left(v_{i}  \right)=\sum_{i=1}^na_iw_i = 0\)


Since $\mathrm{S}$ is L.I. $\implies a_1 = a_2=\cdots = a_n = 0$ 
\end{sol*}
	

\end{example}
\begin{thm*}[2.6]
$ $ \\Let V and W be vector spaces over F, and suppose that \{ $v_1,v_2,\cdots,v_n$ \} is a basis for V. For $w_1,w_2,\cdots,w_n$ in W, there exists exactly one linear transformation $\mathrm{T}: \mathrm{V}  \rightarrow \mathrm{W}$ such that T($v_i$) = $w_i$ for i = 1,2,$\cdots$,n.
\end{thm*}
		
\subsection*{\S\,2-2 The Matrix Representation of a Linear transformation}

\begin{defn}[Definition of an Ordered Basis]
$ $ \\  Let V be a finite-dimensional vector space. An ordered basis for V is a basis for V endowed with a specific order; that is, an ordered basis for V is a finite sequence of linearly independent vectors in V that generates V.
\end{defn}

\newpage
\begin{defn}[Definition for the symbol $\lbrack x \rbrack_\beta$]
$ $\\ Let $\beta = \{ u_1,u_2,\cdots,u_n \}$ be an ordered basis for a finite- dimensional vector space V. For $x \in \mathrm{V}$, let $a_1, a_2, \cdot $, an be the unique scalars such that
$x = \sum_{i=1}^{\mathrm{n}} a_iu_i$
We define the coordinate vector of x relative to $\beta$, denoted $\lbrack x \rbrack_\beta$, by
\begin{center}
	 $\lbrack x \rbrack_\beta = \left[\begin{matrix}
	a_1 \\
	a_2 \\
	\vdots \\
	a_n 	
\end{matrix}\right]$
\end{center}

Notice that $\lbrack u_i \rbrack_\beta = e_i$ in the preceding definition. It is left as an exercise to show that the correspondence $x \rightarrow \lbrack x \rbrack_ \beta$ provides us with a linear transformation from V to $\mathrm{F}^n$. We study this transformation in Section 2.4 in more detail.
\end{defn}

% Textbook 2-2 Exercise 8

\begin{defn}[Definition for the symbol $\lbrack \mathrm{T} \rbrack^\gamma_\beta$] $ $\\
Using the notation above,we call the $\mathrm{m} \times \mathrm{n}$ matrix A defined by $\mathrm{A}_{ij} = \mathrm{a}_{ij}$ the matrix representation of T in the ordered bases $\beta$ and $\gamma$ and write $\mathrm{A} = \lbrack \mathrm{T} \rbrack^\gamma_\beta$. If $\mathrm{V} = \mathrm{W}$ and $\beta = \gamma$, then we write $\mathrm{A} = \lbrack \mathrm{T}\rbrack_\beta$.
Notice that the jth column of A is simply $\lbrack \mathrm{T} (v_j)\rbrack_\gamma$ . Also observe that if
$\mathrm{U} : \mathrm{V} \rightarrow \mathrm{W}$ is a linear transformation such that $\lbrack \mathrm{U} \rbrack^\gamma_\beta = [\mathrm{T}]^\gamma_\beta$, then $\mathrm{U} = \mathrm{T}$ by the corollary to Theorem 2.6 (p. 73).

\end{defn}

\begin{defn}[The addition and multiplication for Linear Transformation] $ $\\
Let $\mathrm{T} , \mathrm{U}: \mathrm{V} \rightarrow \mathrm{W}$ be arbitrary functions, where V and W are vector spaces over F, and let $a \in \mathrm{F}$. We define $\mathrm{T}+\mathrm{U} : \mathrm{V} \rightarrow \mathrm{W}$ by $(\mathrm{T}+\mathrm{U})(x) = \mathrm{T}(x)+\mathrm{U}(x)$ for all $x \in \mathrm{V}$, and $a\mathrm{T}: \mathrm{V} \rightarrow \mathrm{W}$ by $(a\mathrm{T})(x) = a\mathrm{T}(x)$ for all $x \in \mathrm{V}$.


Of course, these are just the usual definitions of addition and scalar multiplication of functions. We are fortunate, however, to have the result that both sums and scalar multiples of linear transformations are also linear.
\end{defn}

	

		
\end{document}